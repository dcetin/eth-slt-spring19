{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLT-CE-1: Locally Linear Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#f0b375;\"> Setup </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from sklearn.manifold import LocallyLinearEmbedding as SklearnLLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#adebad;\">\n",
    "The MNIST data set contains three sets: **mnist.train, mnist.validation, mnist.test**  \n",
    "Each of them is a numpy array with samples along rows, and pixels along columns.   \n",
    "The original shape of the images is 28x28 = 784.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(mnist.train.images[2].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#f0b375;\">\n",
    "Section 4.0 \n",
    "<span style=font-size:50%> Complete all problems in this section to get a pass on this exercise. </span>\n",
    "</h2>\n",
    "\n",
    "<p style=\"background-color:#adebad;\">\n",
    "    Shortly recapitulate the Locally Linear Embedding (LLE) algorithm, and the involved formulas.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea of the LLE algorithm is to learn a non-linear embedding by approximating it with local linear patches. At each point, we do a different linear embedding as the manifold looks linear locally. Implemetation is done accordingly to the [pseudocode](https://cs.nyu.edu/~roweis/lle/algorithm.html) provided by the authors of the original paper.\n",
    "\n",
    "Algorithmically, we iterate over the data points and find neighbors for each point. Using k-nearest neighbors to obtain the local patch gives the advantage of defining the patches adaptively with respect to sample distribution density. There are alternatives to allocate the local patch, e.g. using an epsilon-ball.\n",
    "\n",
    "We solve for the weights that reconstruct the datapoint from its neighbors and set all non-neighbors weights to zero, for every point in the training data set. That is, we first define de local covariance as $ C=Z^T Z $, where $ Z $ is the matrix that consists of all the neighbors of $ X $, then solve for $ Cw = 1 $ and assign the normalized $ w $ values as weights of the neighbors. \n",
    "\n",
    "After computing weights at each data point we create the sparse matrix $ M = (I-W)^T(I-W) $ and get the bottom $d+1$ eigenvectors of it, discarding the bottom eigenvector with eigenvalue zero. This gives the embedding vectors of the original data points.\n",
    "\n",
    "Over the course of the algorithm, we also calculate and save various variables, including the reconstruction error of the embedding and the eigenvalues of the matrix $ M $.\n",
    "\n",
    "Resulting embedding vectors are plotted and labeled alongside the ones obtained from the scikit-learn's implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#adebad;\">\n",
    "    Implement the <b>fit method</b> for the template class LocallyLinearEmbedding, according to the contract outlined in its docstring.<br>\n",
    "    In particular, use the class attribute (variable) names as provided, and introduce new class attributes only if necessary.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocallyLinearEmbedding(skl.base.BaseEstimator, skl.base.TransformerMixin):\n",
    "    \"\"\"Template class for LLE, compare to `sklearn LLE`_.\n",
    "    \n",
    "    Attributes:\n",
    "        embedding_vectors_ (np.ndarray): Embedding of input X with shape (samples, n_components)\n",
    "        nbrs_X (e.g. sklearn.neighbors.KDTree): NearestNeighbors (NN) object, stores NN for training set X.\n",
    "        nbrs_y (e.g. sklearn.neighbors.KDTree): NearestNeighbors (NN) object, stores NN for embedding_vectors_.\n",
    "        M_ (np.array): Symmetric matrix (samples, samples), used in quadratic form for embedding.\n",
    "        X_ (np.array): Copy of training set with shape (samples, dim).\n",
    "    \n",
    "       .. _`sklearn LLE`: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=2, n_neighbors=5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_components = n_components\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Compute LLE embedding of vectors X\n",
    "        \n",
    "        First, compute nbrs_X and M_.\n",
    "        Finally, compute embedding_vectors_.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Input array with shape (samples, dim)\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.X_ = X\n",
    "        self.nbrs_X = skl.neighbors.KDTree(self.X_, leaf_size=100)\n",
    "        \n",
    "        n_items = X.shape[0]\n",
    "        weights = np.zeros((n_items, self.X_.shape[0]))\n",
    "\n",
    "        for i in range(0, n_items):\n",
    "            \n",
    "            # Current datapoint\n",
    "            cur = X[i,:]\n",
    "            \n",
    "            # Find the nearest neighbors\n",
    "            '''\n",
    "            dists = (X - cur)\n",
    "            dists = np.multiply(dists, dists)\n",
    "            dists = np.sum(dists, axis=1)\n",
    "            sorted_dists = np.argsort(dists) # only need the first nn+1 elements, no need to sort it all\n",
    "            n_idxs = sorted_dists[1:self.n_neighbors+1]\n",
    "            print(n_idxs)\n",
    "            '''\n",
    "            # Instead, use the sklearn implementation\n",
    "            dist, ind = self.nbrs_X.query(cur.reshape(1, -1), k=self.n_neighbors+1)\n",
    "            n_idxs = np.setdiff1d(ind[0],[i])\n",
    "            neighbors = self.X_[n_idxs, :]\n",
    "            \n",
    "            # Find the weights\n",
    "            # Implementation 1\n",
    "            '''\n",
    "            cur_weights = np.linalg.lstsq(np.transpose(neighbors), cur, rcond=None)\n",
    "            cur_weights = cur_weights[0] / np.sum(cur_weights[0])\n",
    "            weights[i, n_idxs] = cur_weights\n",
    "            '''\n",
    "            # Implementation 2\n",
    "            '''\n",
    "            matrix_c = np.zeros((self.n_neighbors, self.n_neighbors))\n",
    "            for j in range(0,self.n_neighbors):\n",
    "                for k in range(0,self.n_neighbors):\n",
    "                    matrix_c[j,k] = np.dot(np.transpose(cur - self.X_[n_idxs[j], :]), (cur - self.X_[n_idxs[k], :]))\n",
    "            c_inv = np.linalg.inv(matrix_c)\n",
    "            sum_c_inv = np.sum(c_inv)\n",
    "            for j in range(self.n_neighbors):\n",
    "                weights[i,n_idxs[j]] = np.sum(c_inv[j, :]) / sum_c_inv\n",
    "            '''\n",
    "            # Implementation 3\n",
    "            dists = cur - neighbors\n",
    "            c_inv = np.linalg.inv(np.matmul(dists, np.transpose(dists)))\n",
    "            sum_c_inv = np.sum(c_inv)\n",
    "            for j in range(self.n_neighbors):\n",
    "                weights[i,n_idxs[j]] = np.sum(c_inv[j, :]) / sum_c_inv\n",
    "\n",
    "            # Sanity check for the found weights\n",
    "            if(False):\n",
    "                sanity = np.matmul(weights[i, :], X)\n",
    "                plt.matshow(cur.reshape(28,28))\n",
    "                plt.show()\n",
    "                plt.matshow(sanity.reshape(28,28))\n",
    "                plt.show()\n",
    "\n",
    "        self.weights = weights\n",
    "        #print('Finished calculating weights')\n",
    "        \n",
    "        # Implementation 1: Compute the embeddings and the reconstruction error\n",
    "        matrix_i = np.identity(n_items)\n",
    "        i_w = matrix_i - weights\n",
    "        matrix_m = np.matmul(np.transpose(i_w), i_w)\n",
    "        \n",
    "        # Get the eigenvectors using svd\n",
    "        '''\n",
    "        u, s, vh = np.linalg.svd(matrix_m)\n",
    "        y = u[:,-(self.n_components+1):-1]\n",
    "        self.recon_error = np.sum(s[-(self.n_components+1):-1])\n",
    "        '''\n",
    "        \n",
    "        # Implementation 2: Get the eigenvectors using eigh\n",
    "        s, u = np.linalg.eigh(matrix_m)\n",
    "        #arg_s = np.flip(np.argsort(s))\n",
    "        #v = u[:,arg_s]\n",
    "        y = u[:,1:(self.n_components+1)]\n",
    "        self.recon_error = np.sum(s[1:(self.n_components+1)])\n",
    "        self.m_eigvals = s\n",
    "        \n",
    "        # Alter the columns so we can compare the implementation to that of sk-learn\n",
    "        #y = y[:,::-1]\n",
    "        #y[:,:] = -y[:,:]\n",
    "        y[:,0] = -y[:,0]\n",
    "        \n",
    "        # Set the class variables\n",
    "        self.embedding_vectors_ = y\n",
    "        self.M_ = matrix_m\n",
    "        self.nbrs_y = skl.neighbors.KDTree(self.embedding_vectors_, leaf_size=100)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Map new vectors X to embedding space\n",
    "        \n",
    "        Use the fitted model to map new vectors to the space with dimension n_components.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Input array with shape (new_samples, dim)\n",
    "            \n",
    "        Returns:\n",
    "            y (np.ndarray): Embedded vectors with shape (new_samples, n_components)\n",
    "        \"\"\"\n",
    "\n",
    "        check_is_fitted(self, [\"embedding_vectors_\", \"nbrs_X\"])\n",
    "\n",
    "        n_items = X.shape[0]\n",
    "        weights = np.zeros((n_items, self.X_.shape[0]))\n",
    "        for i in range(0, n_items):\n",
    "            \n",
    "            # Current datapoint\n",
    "            cur = X[i,:]\n",
    "            \n",
    "            # Find the nearest neighbors\n",
    "            dist, ind = self.nbrs_X.query(cur.reshape(1, -1), k=self.n_neighbors+1)\n",
    "            n_idxs = np.setdiff1d(ind[0],[i])\n",
    "            neighbors = self.X_[n_idxs, :]\n",
    "            \n",
    "            # Find the weights\n",
    "            cur_weights = np.linalg.lstsq(np.transpose(neighbors), cur, rcond=-1)\n",
    "            cur_weights = cur_weights[0] / np.sum(cur_weights[0])\n",
    "            weights[i, n_idxs] = cur_weights\n",
    "\n",
    "        #print('Finished calculating weights')\n",
    "        \n",
    "        # Find the embeddings\n",
    "        y = np.matmul(weights, self.embedding_vectors_)\n",
    "        return y\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        \"\"\"Map new vectors y to input space with dimension dim.\n",
    "        \n",
    "        Use the fitted model to map vectors y to the original input space.\n",
    "        \n",
    "        Args:\n",
    "            y (np.ndarray): Input array with shape (new_samples, n_components)\n",
    "            \n",
    "        Returns:\n",
    "            X (np.ndarray): Vectors with shape (new_samples, dim)\n",
    "        \"\"\"\n",
    "\n",
    "        check_is_fitted(self, [\"embedding_vectors_\", \"X_\", \"nbrs_y\"])\n",
    " \n",
    "        n_items = y.shape[0]\n",
    "        weights = np.zeros((n_items, self.embedding_vectors_.shape[0]))\n",
    "\n",
    "        for i in range(0, n_items):\n",
    "            \n",
    "            # Current datapoint\n",
    "            cur = y[i,:]\n",
    "\n",
    "            # Find the neighbors\n",
    "            dist, ind = self.nbrs_y.query(cur.reshape(1, -1), k=self.n_neighbors+1)\n",
    "            n_idxs = np.setdiff1d(ind[0],[i])\n",
    "            neighbors = self.embedding_vectors_[n_idxs, :]\n",
    "            \n",
    "            # Find the weights\n",
    "            cur_weights = np.linalg.lstsq(np.transpose(neighbors), cur, rcond=-1)\n",
    "            cur_weights = cur_weights[0] / np.sum(cur_weights[0])\n",
    "            weights[i, n_idxs] = cur_weights\n",
    "\n",
    "        self.weights = weights\n",
    "        #print('Finished calculating weights')\n",
    "        \n",
    "        # Find the inverse transforms\n",
    "        X = np.matmul(weights, self.X_)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#adebad;\">\n",
    "    Create an instance of your LLE class with default parameters and fit the MNIST validation set. Record the execution time (should be about 30 sec). Furthermore, create an instance of the sklearn LLE class, and fit it with the same parameters. Again record the execution time.  \n",
    "    Note, the dots should be filled in by you.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "myLLE = LocallyLinearEmbedding()\n",
    "myLLE.fit(mnist.validation.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sklLLE = SklearnLLE(random_state=42)\n",
    "sklLLE.fit(mnist.validation.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#adebad;\">\n",
    "    Plot myLLE.embedding_vectors_ and sklLLE.embedding_vectors_ in two separate plots.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_mnist(embedding, of=\"validation\"):\n",
    "    labels = getattr(mnist, of).labels\n",
    "\n",
    "    if len(labels) != len(embedding):\n",
    "        raise ValueError(\"Number of labels does not match number of embeddings\")\n",
    "    \n",
    "    for label in range(10):\n",
    "        idx = (labels == label)\n",
    "        plt.scatter(embedding[idx, 0], embedding[idx, 1], alpha=0.5, label=str(label))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(121)\n",
    "plt_mnist(sklLLE.embedding_)\n",
    "plt.subplot(122)\n",
    "plt_mnist(myLLE.embedding_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fit - Errors w.r.t. sklearn implementation: ')\n",
    "print('Avg. error:', np.average(np.abs(sklLLE.embedding_ - myLLE.embedding_vectors_)))\n",
    "print('Max. erorr:', np.max(np.abs(sklLLE.embedding_ - myLLE.embedding_vectors_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#f0b375;\"> Section 4.5\n",
    "<span style=font-size:50%> Complete all problems in this and previous sections to get a 4.5 on this exercise. </span>\n",
    "</h2>\n",
    "\n",
    "<p style=\"background-color:#adebad;\">\n",
    "    <ul style=\"background-color:#adebad;\">\n",
    "        <li> Implement the <b>transform method</b> for the template class LocallyLinearEmbedding, according to the contract outlined in its docstring.\n",
    "        </li>\n",
    "        -\n",
    "        <li> Fit both, myLLE and sklLLE on the MNIST validation set, and use the fitted model to transform the MNIST test set.\n",
    "        </li>\n",
    "        -\n",
    "        <li>\n",
    "            Plot both embeddings in two separate plots for comparison.\n",
    "        </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea behind the **transform** method is quite straightforward, having implemented the **fit** method. We look for the neighbors of the new (unseen) data point in the training data set and solve for its weights. This time implementation uses a least square solver to solve the linear system. Then, we use the calculated weights on the original embedding vectors to obtain the embedding of the new data point, hoping the local approximation would be satisfactory. User can again compare the results of the implementation provided here against the scikit-learn's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_embedding = myLLE.transform(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "skl_embedding = sklLLE.transform(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the plots here\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(121)\n",
    "plt_mnist(skl_embedding, of='test')\n",
    "plt.subplot(122)\n",
    "plt_mnist(my_embedding, of='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Transform - Errors w.r.t. sklearn implementation: ')\n",
    "print('Avg. error:', np.average(np.abs(skl_embedding - my_embedding)))\n",
    "print('Max. erorr:', np.max(np.abs(skl_embedding - my_embedding)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#f0b375;\"> Section 5.0\n",
    "<span style=font-size:50%> Complete all problems in this and previous sections to get a 5.0 on this exercise. </span>\n",
    "</h2>\n",
    "\n",
    "<ul style=\"background-color:#adebad;\">\n",
    "    <li> Think how you can invert the LLE embedding, and shortly describe your approach.</li>\n",
    "        <li> Using your approach, implement the <b>inverse_transform method</b> for the template class LocallyLinearEmbedding, according to the contract outlined in its docstring.\n",
    "        </li>\n",
    "        <li>\n",
    "        Use myLLE.transform and myLLE.inverse_transform to embed the first digit of the MNIST training set and then recover it. \n",
    "        </li>\n",
    "       \n",
    "   </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**inverse_transform** method implements a strategy quite similar to that we followed through in **transform** method. This time, we want to obtain the data point in the original manifold, given its embedding in the d-dimensional space we have constructed in **fit**. We find the neighboring embeddings for a given embedding, obtain the reconstruction weights using a least square solver, then use these weights to approximate the data point in the original manifold using the weighted sum of the original data points that correspond the neighboring embeddings. It is the same strategy in **transform**, as we have indicated earlier, using embeddings to transform a new embedding into the original manifold instead of vice-versa. Authors also argue that regularisation could be of help when there are more neighbors than input dimensions ($k \\geq d$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_idx = 1\n",
    "embedded_digit = myLLE.transform(np.asarray([mnist.train.images[digit_idx]]))\n",
    "reconstructed_digit = myLLE.inverse_transform(embedded_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"background-color:#adebad;\">\n",
    "    <li>\n",
    "        Plot the original digit and the reconstructed digit for comparison.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(mnist.train.images[digit_idx].reshape(28,28))\n",
    "plt.subplot(122)\n",
    "plt.imshow(reconstructed_digit[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#f0b375;\"> Section 5.5\n",
    "<span style=font-size:50%> Complete all problems in this and previous sections to get a 5.5 on this exercise. </span>\n",
    "</h2>\n",
    "\n",
    "<ul style=\"background-color:#adebad;\">\n",
    "        <li>\n",
    "        Perform a grid search of the reconstruction error, i.e. the sum of the k lowest eigenvalues of matrix M_ (with k=n_components), over the parameters n_neighbors, and n_components.  \n",
    "        Create a nice 2D heatmap of the results.\n",
    "        </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_neighbors = [3,4,5,7,10]\n",
    "list_components = [2,4,6,8,10]\n",
    "my_errormap = np.zeros((len(list_neighbors), len(list_components)))\n",
    "for i, nn in enumerate(list_neighbors):\n",
    "    for j, nc in enumerate(list_components):\n",
    "        # Fit the embeddings\n",
    "        myLLE = LocallyLinearEmbedding(n_components=nc, n_neighbors=nn)\n",
    "        myLLE.fit(mnist.validation.images)\n",
    "        my_errormap[i,j] = myLLE.recon_error\n",
    "        print(nn, nc, myLLE.recon_error)\n",
    "        '''\n",
    "        # Sanity check: calculate the errors\n",
    "        YtMY = np.matmul(np.transpose(myLLE.embedding_vectors_), np.matmul(myLLE.M_, myLLE.embedding_vectors_))\n",
    "        u, s, vh = np.linalg.svd(myLLE.M_)\n",
    "        YtMY_error = np.trace(YtMY)\n",
    "        trm_error = np.sum(s[-(nc+1):-1])\n",
    "        fro_error = np.linalg.norm(myLLE.embedding_vectors_- np.matmul(myLLE.weights, myLLE.embedding_vectors_), 'fro')**2\n",
    "        print(myLLE.recon_error, YtMY_error, trm_error, fro_error)\n",
    "        ''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstrution error increases with both n_components and n_neighbors. This is natural as we add entries to the sum by increasing both values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(my_errormap, cmap='hot')\n",
    "plt.xticks( range(len(list_components)), list_components )\n",
    "plt.xlabel('n_components')\n",
    "plt.yticks( range(len(list_neighbors)), list_neighbors )\n",
    "plt.ylabel('n_neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"background-color:#adebad;\">\n",
    "        <li>\n",
    "        Create a matrix plot of the matrix M_.  \n",
    "        Make sure to permute the rows and columns according to the digit labels, so that you can actually observe the block structure. Also make sure to scale the plot properly, so that you can observe the block structure. What is the origin of the block structure?\n",
    "        </li>\n",
    "        <li>\n",
    "        Plot the spectrum (eigenvalues) of M_. Can you identify a good cutoff? What could you use the value of the cutoff for?\n",
    "        </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the fit method one more time to obtain results that are comparable in the sections preceding the grid search, i.e. we would again be using default parameters for the algorithm in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLLE = LocallyLinearEmbedding()\n",
    "myLLE.fit(mnist.validation.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows and columns are ordered accordingly to the digit labels. White pixels denote the non-zero entries whereas the black pixels denote the zeroes. Origin of the block structure is the labels having neighbors moslty from their own labels, as non-zero entries are neighbor weights.\n",
    "\n",
    "We can see that 0 having a denser block than rest as intraclass variation w.r.t. shape is small for 0s, making the digits clustered in the embedding space. Similarly, block for 5 is perhaps the most sparse block in the matrix, indicating that the digits being most distorted by the transformation. Additionally, 4s or 8s only having neighbors (aside from their own labels) with 9s is intuitive by the similarity of the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getattr(mnist, 'validation').labels\n",
    "arg_lab = np.argsort(labels)\n",
    "matrix_m = myLLE.M_\n",
    "matrix_m[0] = np.inf\n",
    "matrix_m = matrix_m[arg_lab,:]\n",
    "matrix_m = matrix_m[:, arg_lab]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(matrix_m, cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is illustrated the eigenvalues of the matrix M in ascending order. Looking at the zoomed in chart on the right side, 8 eigenvalues seems to be a good cutoff, although one can argue on different cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals = myLLE.m_eigvals\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(eigvals)\n",
    "plt.xlabel('Spectrum index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.subplot(122)\n",
    "plt.plot(eigvals[:20])\n",
    "plt.xticks(range(0,len(eigvals[:20])))\n",
    "plt.xlabel('Spectrum index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#f0b375;\"> Section 6.0\n",
    "<span style=font-size:50%> Complete all problems in this and previous sections to get a 6.0 on this exercise. </span>\n",
    "</h2>\n",
    "\n",
    "<ul style=\"background-color:#adebad;\">\n",
    "        <li>\n",
    "        Plot the linear interpolation between two digits $x_1,\\ x_2$ in the input space compared to the reconstruction along the linear interpolation of their embeddings $y_1, y_2$. More precisely, compare $\\lambda x_1 + (1-\\lambda) x_2,\\ \\lambda\\in[0,1]$ to $LLE^{-1}\\big(\\lambda y_1 + (1-\\lambda) y_2\\big),\\ \\lambda\\in[0,1]$\n",
    "        </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plt_with_bg plots** a trajectory along a series of embeddings on top of provided background embeddings with class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_with_bg(fg_embedding, fg_tag, bg_embedding, of=\"validation\"):\n",
    "    labels = getattr(mnist, of).labels\n",
    "    if len(labels) != len(bg_embedding):\n",
    "        raise ValueError(\"Number of labels does not match number of embeddings\")\n",
    "    for label in range(10):\n",
    "        idx = (labels == label)\n",
    "        xs = bg_embedding[idx, 0]\n",
    "        ys = bg_embedding[idx, 1]\n",
    "        plt.scatter(xs[::], ys[::], alpha=0.2, label=str(label))\n",
    "\n",
    "    plt.plot(fg_embedding[:, 0], fg_embedding[:, 1], alpha=0.9, label=fg_tag, marker='o',\n",
    "             markerfacecolor='w', markeredgewidth=1.5, markeredgecolor='k')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plt_interpolate plots** the interpolation of two images and the inverse transform of their interpolated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_interpolate(d1, d2):\n",
    "    embed_list = []\n",
    "    # Set the discretization level\n",
    "    k = 15\n",
    "    # Plot the linear interpolation\n",
    "    plt.figure(figsize=(15,1))\n",
    "    weight = np.linspace(0, 1, num=k)\n",
    "    for i in range(0,k):\n",
    "        plt.subplot(1, k, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow((d2*weight[i] + d1*(1-weight[i])).reshape(28,28), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    # Plot the linear interpolation of their embeddings\n",
    "    plt.figure(figsize=(15,1))\n",
    "    weight = np.linspace(0, 1, num=k)\n",
    "    for i in range(0,k):\n",
    "        plt.subplot(1, k, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        embedded = myLLE.transform(np.asarray([d2]))*weight[i] + myLLE.transform(np.asarray([d1]))*(1-weight[i])\n",
    "        plt.imshow(( myLLE.inverse_transform(embedded)[0] ).reshape(28,28), cmap=plt.cm.gray)\n",
    "        embed_list.append(embedded)\n",
    "    plt.show()\n",
    "    embed_list = np.concatenate(embed_list, axis=0)\n",
    "    return embed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation of the two images of the same digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = mnist.train.images[1]\n",
    "d2 = mnist.train.images[11]\n",
    "embed_list = plt_interpolate(d1, d2)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt_with_bg(embed_list, 'ip3-3', myLLE.embedding_vectors_, of=\"validation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation of images of different digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = mnist.train.images[1]\n",
    "d2 = mnist.train.images[2]\n",
    "embed_list = plt_interpolate(d1, d2)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt_with_bg(embed_list, 'ip3-4', myLLE.embedding_vectors_, of=\"validation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"background-color:#adebad;\">\n",
    "        <li>\n",
    "        Select images of digits \"6\" and a digits \"8\".  \n",
    "        Rotate the input images by 360° in steps of 1° and create the embedding of each rotation.  \n",
    "        Create a nice plot of the respective trajectories in the 2D embedding space (Make sure to use markers for the embeddings, and connect them with a line. Use labels and legends, and add some embeddings of other digits to put the trajectories into context).\n",
    "        </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function anim.to_html5_video() may not work if the ffmpeg codec (or any alternative one) is not installed properly.\n",
    "Similarly, anim.to_jshtml() might not work as it requires considerable memory to create interactive plots.\n",
    "\n",
    "If for any other reason the animations do not work, user can view the static plots below the animated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**rotate_and_embed** rotates the given image 360° in steps of 1°, then creates and returns the embeddings of the rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_embed(img,angle_step):\n",
    "    rot_list = []\n",
    "    org_size = img.shape\n",
    "    for degree in range(0,360,angle_step):\n",
    "        rotated_img = ndimage.rotate(img, angle=degree, order=1, reshape=False, axes=(0,1))\n",
    "        '''\n",
    "        # Alternative implementation\n",
    "        rotated_img = ndimage.rotate(img, degree)\n",
    "        size_diff = np.subtract(rotated_img.shape, org_size)[0]\n",
    "        i = size_diff//2\n",
    "        j = size_diff - size_diff//2\n",
    "        rlen = rotated_img.shape[0]\n",
    "        rotated_img = rotated_img[i:rlen-j,i:rlen-j]   \n",
    "        '''\n",
    "        rot_list.append(rotated_img.flatten())\n",
    "        if(False):\n",
    "            print(degree, rotated_img.shape, size_diff)\n",
    "            plt.figure()\n",
    "            plt.imshow(rotated_img, cmap=plt.cm.gray)\n",
    "            plt.show()\n",
    "    res_list = np.stack(rot_list, axis=0)\n",
    "    res_list = myLLE.transform(res_list)\n",
    "\n",
    "    return rot_list, res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plt_rotate_animate** creates both animations for rotating image itself and the trajectory of its embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_rotate_animate(digit, tag):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12, 10, True)\n",
    "    ax[0].set_xlim((-0.02, 0.04))\n",
    "    ax[0].set_ylim((-0.05, 0.04))\n",
    "\n",
    "    labels = getattr(mnist, 'validation').labels\n",
    "    for label in range(10):\n",
    "        idx = (labels == label)\n",
    "        xs = myLLE.embedding_vectors_[idx, 0]\n",
    "        ys = myLLE.embedding_vectors_[idx, 1]\n",
    "        ax[0].scatter(xs, ys, alpha=0.2, label=str(label))\n",
    "\n",
    "    xdata, ydata = [], []\n",
    "    line, = ax[0].plot([], [], alpha=1, label=tag, marker='o', markerfacecolor='w', markeredgewidth=1.5, markeredgecolor='k')\n",
    "    ax[0].legend()\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        return (line,)\n",
    "    def animate(i):\n",
    "        xdata.append(rot_embedding[i, 0])\n",
    "        ydata.append(rot_embedding[i, 1])\n",
    "        line.set_data(xdata, ydata)\n",
    "        global x, y\n",
    "        x += np.pi / 15.\n",
    "        y += np.pi / 20.\n",
    "        im.set_array(f(x, y))\n",
    "        im.set_array(rot_imgs[i].reshape(28,28))\n",
    "        return (line,im,)\n",
    "\n",
    "    def f(x, y):\n",
    "        return np.sin(x) + np.cos(y)\n",
    "\n",
    "    x = np.linspace(0, 2 * np.pi, 120)\n",
    "    y = np.linspace(0, 2 * np.pi, 100).reshape(-1, 1)\n",
    "\n",
    "    im = ax[1].imshow(f(x, y), animated=True)\n",
    "\n",
    "    rot_imgs, rot_embedding = rotate_and_embed(digit, 1)\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=360, interval=100, blit=True)\n",
    "\n",
    "    #HTML(anim.to_html5_video())\n",
    "    #HTML(anim.to_jshtml())\n",
    "    \n",
    "    return anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animation showing the movement in the embedding space corresponding the rotating image given to its right. This example uses an image of the digit 6 . It is in line with our expectations that the upside down image should be embedded near 9 s in the embedding space. It stays there for a considerable amount and returns to its original place as the image nears to complete its rotation. The intermediary movements are harder to explain intuitively as they do not quite look like any of the digits in the training data set the movement is naturally erratic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six = mnist.train.images[3].reshape(28,28)\n",
    "anim = plt_rotate_animate(six, 'rot6')\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The situation here with an exemplary image of 8 is similar to what we have explained above, but even more irregular. We can visually confirm the embedding return near the original position when the rotation angle is around 180°, as well as when it is aroudn 360°. In the intermediary steps, its movement is more unpredictable than in the former example as we now deal with a more complicated shape in the original manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight = mnist.train.images[5].reshape(28,28)\n",
    "anim = plt_rotate_animate(eight, 'rot8')\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the cell below for the static plots, if the animated plots do not display properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six = mnist.train.images[3].reshape(28,28)\n",
    "eight = mnist.train.images[5].reshape(28,28)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(121)\n",
    "plt_with_bg(rotate_and_embed(six, 1)[1], 'rot6', myLLE.embedding_vectors_, of='validation')\n",
    "plt.subplot(122)\n",
    "plt_with_bg(rotate_and_embed(eight, 1)[1], 'rot8', myLLE.embedding_vectors_, of='validation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
